{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sorry Eh\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from fuzzywuzzy import fuzz\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "news='Supreme Court to study plea for food for all'\n",
    "sent1=news.split()\n",
    "results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Hindu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.thehindu.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching News Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC to study petition for food for all\n",
      "Top news of the day: 4 killed in Navi Mumbai ONGC plant fire, Chidambaram to remain in CBI custody till September 5, and more\n",
      "Supreme Court to study plea for food for all\n",
      "Life after rescue: in West Bengal's human trafficking hub\n",
      "Life after rescue\n",
      "MGNREGA compensation delayed by Centre or states in around 50% cases: study\n",
      "Don’t let messengers shoot themselves\n",
      "As it happened: Rajya Sabha passes loan recovery Bill\n",
      "Illegal arrest a blow to individual dignity, says SC\n",
      "On death row, dying many deaths\n"
     ]
    }
   ],
   "source": [
    "link_path='//*[@id=\"GA-tracking-top\"]/div[2]/form/input[1]'\n",
    "elem=driver.find_element_by_xpath(link_path)\n",
    "elem.send_keys(news)\n",
    "elem.submit()\n",
    "for j in range(1,11):\n",
    "    res='//*[@id=\"scrolladvanced\"]/div[3]/div[3]/section/div['+str(j)+']/div/div/div[1]/a'\n",
    "    result=driver.find_element_by_xpath(res)\n",
    "    print(result.text)\n",
    "    sent2=result.text\n",
    "    sent2=sent2.split()\n",
    "    sentvectors1 = calc_avg_w2v([sent1],google_w2v)\n",
    "    sentvectors2 = calc_avg_w2v([sent2],google_w2v)\n",
    "    #print(cosine_similarity(sentvectors1,sentvectors2)[0][0])\n",
    "    if (cosine_similarity(sentvectors1,sentvectors2)[0][0]>0.75):\n",
    "        results.append(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SC to study petition for food for all',\n",
       " 'Supreme Court to study plea for food for all']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Times Of india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://timesofindia.indiatimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything going according to plan: Isro chief\n",
      "Moment 130 cr Indians waiting for is here: PM\n",
      "Why BSY is not rejoicing over DKS's arrest\n",
      "Bianca, the teenager who will look to stop Serena\n",
      "Want US citizenship? Social media IDs, please\n",
      "5-ft cobra slips into bungalow toilet, rescued\n",
      "Turkish duo held for 60 ATM frauds in Assam\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    link_path='//*[@id=\"content\"]/div/div[6]/ul/li['+str(i)+']/a'\n",
    "    elem=driver.find_element_by_xpath(link_path)\n",
    "    print(elem.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching News Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ayodhya: SC to hear Rajeev Dhavan's contempt plea against ex-govt official for threatening him\n",
      "Supreme Court to hear BJP’s yatra plea on January 8\n",
      "Supreme Court to hear plea on social media hub\n",
      "All eyes on SC ahead of CBI chief's plea against govt order\n",
      "Pleas against CLAT 2018: SC seeks solution to complaints of candidates\n",
      "SC to hear tomorrow pleas challenging CLAT 2018 examination\n",
      "SC seeks Centre's reply on Shia Waqf Board's plea against 'un-Islamic' flags\n",
      "Foreigner or citizen? Assam finds out at stroke of midnight on Dec 31\n"
     ]
    }
   ],
   "source": [
    "link_path='//*[@id=\"header\"]/div[2]/div[2]/div/span'\n",
    "elem=driver.find_element_by_xpath(link_path).click()\n",
    "link_path='//*[@id=\"query\"]'\n",
    "elem=driver.find_element_by_xpath(link_path)\n",
    "elem.send_keys(news)\n",
    "elem.submit()\n",
    "link_path='//*[@id=\"news\"]'\n",
    "elem=driver.find_element_by_xpath(link_path).click()\n",
    "for i in range(1,11):\n",
    "    link_path='//*[@id=\"c_topic_list1_1\"]/div[1]/ul/li['+str(i)+']/div/a/span[1]'\n",
    "    try:\n",
    "        result=driver.find_element_by_xpath(link_path)\n",
    "        print(result.text)\n",
    "        sent2=result.text\n",
    "        sent2=sent2.split()\n",
    "        sentvectors1 = calc_avg_w2v([sent1],google_w2v)\n",
    "        sentvectors2 = calc_avg_w2v([sent2],google_w2v)\n",
    "        #print(cosine_similarity(sentvectors1,sentvectors2)[0][0])\n",
    "        if (cosine_similarity(sentvectors1,sentvectors2)[0][0]>0.75):\n",
    "            results.append(result.text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SC to study petition for food for all',\n",
       " 'Supreme Court to study plea for food for all',\n",
       " 'SC to study petition for food for all',\n",
       " 'Supreme Court to study plea for food for all']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BBC News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bbc.com/news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_path='//*[@id=\"orb-search-q\"]'\n",
    "elem=driver.find_element_by_xpath(link_path)\n",
    "elem.send_keys(news)\n",
    "elem.submit()\n",
    "for j in range(1,11):\n",
    "    res='//*[@id=\"search-content\"]/ol/li['+str(j)+']/article/div/h1/a'\n",
    "    try:\n",
    "        result=driver.find_element_by_xpath(res)\n",
    "        print(result.text)\n",
    "        sent2=result.text\n",
    "        sent2=sent2.split()\n",
    "        sentvectors1 = calc_avg_w2v([sent1],google_w2v)\n",
    "        sentvectors2 = calc_avg_w2v([sent2],google_w2v)\n",
    "        print(cosine_similarity(sentvectors1,sentvectors2)[0][0])\n",
    "        if (cosine_similarity(sentvectors1,sentvectors2)[0][0]>0.75):\n",
    "            results.append(result.text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.dnaindia.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"gsc-thumbnail-inside\"><div class=\"gs-title\"><a class=\"gs-title\" href=\"https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006\" target=\"_parent\" dir=\"ltr\" data-cturl=\"https://www.google.com/url?client=internal-uds-cse&amp;cx=partner-pub-8331061652869281:jrt9zf-p1ic&amp;q=https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006&amp;sa=U&amp;ved=2ahUKEwjem_WYub7kAhXRgUsFHXt5ARUQFjAAegQIBhAC&amp;usg=AOvVaw2m6hdREks6Y7uIIUELBxKA\" data-ctorig=\"https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006\">Gujarat <b>High Court</b> issues notice to state over <b>pleas</b> challenging ...</a></div></div><div class=\"gsc-url-top\"><div class=\"gs-bidi-start-align gs-visibleUrl gs-visibleUrl-short\" dir=\"ltr\">www.dnaindia.com</div><div class=\"gs-bidi-start-align gs-visibleUrl gs-visibleUrl-long\" dir=\"ltr\" style=\"word-break:break-all;\">https://www.dnaindia.com/.../report-gujarat-<b>high</b>-<b>court</b>-issues-notice-to-state- over-<b>pleas</b>-ch<b>all</b>enging-alcohol-prohibition-2723006</div></div><div class=\"gsc-table-result\"><div class=\"gsc-table-cell-thumbnail gsc-thumbnail\" style=\"\"><div class=\"gs-image-box gs-web-image-box gs-web-image-box-landscape\"><a class=\"gs-image\" href=\"https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006\" target=\"_parent\" data-cturl=\"https://www.google.com/url?client=internal-uds-cse&amp;cx=partner-pub-8331061652869281:jrt9zf-p1ic&amp;q=https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006&amp;sa=U&amp;ved=2ahUKEwjem_WYub7kAhXRgUsFHXt5ARUQFjAAegQIBhAC&amp;usg=AOvVaw2m6hdREks6Y7uIIUELBxKA\" data-ctorig=\"https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006\"><img class=\"gs-image\" onload=\"if (this.parentNode &amp;&amp; this.parentNode.parentNode &amp;&amp; this.parentNode.parentNode.parentNode) { this.parentNode.parentNode.parentNode.style.display = ''; this.parentNode.parentNode.className = 'gs-image-box gs-web-image-box gs-web-image-box-landscape'; } \" src=\"https://cdn.dnaindia.com/sites/default/files/styles/square/public/2019/02/23/794612-liquor-012917.jpg\"></a></div></div><div class=\"gsc-table-cell-snippet-close\"><div class=\"gs-title gsc-table-cell-thumbnail gsc-thumbnail-left\"><a class=\"gs-title\" href=\"https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006\" target=\"_parent\" dir=\"ltr\" data-cturl=\"https://www.google.com/url?client=internal-uds-cse&amp;cx=partner-pub-8331061652869281:jrt9zf-p1ic&amp;q=https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006&amp;sa=U&amp;ved=2ahUKEwjem_WYub7kAhXRgUsFHXt5ARUQFjAAegQIBhAC&amp;usg=AOvVaw2m6hdREks6Y7uIIUELBxKA\" data-ctorig=\"https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006\">Gujarat <b>High Court</b> issues notice to state over <b>pleas</b> challenging ...</a></div><div><span></span></div><div class=\"gs-bidi-start-align gs-snippet\" dir=\"ltr\">Feb 23, 2019 <b>...</b> The senior advocate also pointed out that <b>every</b> person has a right ... The Gujarat \n",
      "<b>High Court</b> on Friday finally sought a reply from the ... Kavina pointed out to the \n",
      "court that alcohol comes under the definition of '<b>food</b>' under the&nbsp;...</div><div class=\"gsc-url-bottom\"><div class=\"gs-bidi-start-align gs-visibleUrl gs-visibleUrl-short\" dir=\"ltr\">www.dnaindia.com</div><div class=\"gs-bidi-start-align gs-visibleUrl gs-visibleUrl-long\" dir=\"ltr\" style=\"word-break:break-all;\">https://www.dnaindia.com/.../report-gujarat-<b>high</b>-<b>court</b>-issues-notice-to-state- over-<b>pleas</b>-ch<b>all</b>enging-alcohol-prohibition-2723006</div></div><div class=\"gs-richsnippet-box\" style=\"display: none;\"></div><div class=\"gs-per-result-labels\" url=\"https://www.dnaindia.com/ahmedabad/report-gujarat-high-court-issues-notice-to-state-over-pleas-challenging-alcohol-prohibition-2723006\"></div></div></div>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(1,11):\\n    link_path=\\'//*[@id=\"___gcse_0\"]/div/div/div/div[5]/div[2]/div/div/div[\\'+str(i)+\\']/div[1]/div[1]/div/a\\'\\n    try:\\n        result=driver.find_element_by_xpath(link_path)\\n        print(result.text)\\n        sent2=result.text\\n        sent2=sent2.split()\\n        sentvectors1 = calc_avg_w2v([sent1],google_w2v)\\n        sentvectors2 = calc_avg_w2v([sent2],google_w2v)\\n        #print(cosine_similarity(sentvectors1,sentvectors2)[0][0])\\n        if (cosine_similarity(sentvectors1,sentvectors2)[0][0]>0.75):\\n            results.append(result.text)\\n    except:\\n        pass\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_path='//*[@id=\"hdrscl\"]/div[1]/i'\n",
    "elem=driver.find_element_by_xpath(link_path).click()\n",
    "sleep(3)\n",
    "link_path='//*[@id=\"hdrscl\"]/div[2]/form/input'\n",
    "elem=driver.find_element_by_xpath(link_path)\n",
    "elem.send_keys(news)\n",
    "elem.submit()\n",
    "atags = driver.find_elements_by_css_selector('#___gcse_0 > div > div > div > div.gsc-wrapper > div.gsc-resultsbox-visible > div > div > div.gsc-webResult.gsc-result > div.gs-webResult.gs-result ')\n",
    "for a in atags:\n",
    "     print (a.get_attribute('innerHTML'))\n",
    "\n",
    "'''\n",
    "for i in range(1,11):\n",
    "    link_path='//*[@id=\"___gcse_0\"]/div/div/div/div[5]/div[2]/div/div/div['+str(i)+']/div[1]/div[1]/div/a'\n",
    "    try:\n",
    "        result=driver.find_element_by_xpath(link_path)\n",
    "        print(result.text)\n",
    "        sent2=result.text\n",
    "        sent2=sent2.split()\n",
    "        sentvectors1 = calc_avg_w2v([sent1],google_w2v)\n",
    "        sentvectors2 = calc_avg_w2v([sent2],google_w2v)\n",
    "        #print(cosine_similarity(sentvectors1,sentvectors2)[0][0])\n",
    "        if (cosine_similarity(sentvectors1,sentvectors2)[0][0]>0.75):\n",
    "            results.append(result.text)\n",
    "    except:\n",
    "        pass\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AP news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "news='johnson suspends UK parliament after latest brexit defeat'\n",
    "sent1=news.split()\n",
    "results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnson suspends UK Parliament after latest Brexit defeat\n",
      "Johnson suspends UK Parliament after latest Brexit defeat\n"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://www.apnews.com/\")\n",
    "link_path='//*[@id=\"root\"]/div/main/div[1]/div[1]/nav/ol/li[5]/div'\n",
    "elem=driver.find_element_by_xpath(link_path).click()\n",
    "driver.find_element_by_xpath('//*[@id=\"root\"]/div/main/div[1]/div[2]/div/div/input').send_keys(news)\n",
    "driver.find_element_by_xpath('//*[@id=\"root\"]/div/main/div[1]/div[2]/div/div/input').send_keys(Keys.RETURN)\n",
    "sleep(2)\n",
    "\n",
    "for j in range(1,11):\n",
    "    try:\n",
    "        res='//*[@id=\"root\"]/div/main/div[1]/div[2]/div/div/section/section/div/div/ul/li['+str(j)+']/a'\n",
    "        result=driver.find_element_by_xpath(res)\n",
    "        print(result.text)\n",
    "        sent2=result.text\n",
    "        sent2=sent2.split()\n",
    "        sentvectors1 = calc_avg_w2v([sent1],google_w2v)\n",
    "        sentvectors2 = calc_avg_w2v([sent2],google_w2v)\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the bureau investigates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "news='Revealed: How the global beef trade is destroying the Amazon'\n",
    "sent1=news.split()\n",
    "results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food and Farming\n",
      "Revealed: How the global beef trade is destroying the Amazon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Gore\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homepage\n"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://www.thebureauinvestigates.com/\")\n",
    "link_path='/html/body/header/div/div/div[1]'\n",
    "elem=driver.find_element_by_xpath(link_path).click()\n",
    "driver.find_element_by_xpath('/html/body/div[3]/div/div/form/input[1]').send_keys(news)\n",
    "driver.find_element_by_xpath('/html/body/div[3]/div/div/form/input[1]').send_keys(Keys.RETURN)\n",
    "sleep(2)\n",
    "\n",
    "for j in range(1,11):\n",
    "    try:\n",
    "        res='/html/body/div[4]/div/a['+str(j)+']/div[2]/p'\n",
    "        result=driver.find_element_by_xpath(res)\n",
    "        print(result.text)\n",
    "        sent2=result.text\n",
    "        sent2=sent2.split()\n",
    "        sentvectors1 = calc_avg_w2v([sent1],google_w2v)\n",
    "        sentvectors2 = calc_avg_w2v([sent2],google_w2v)\n",
    "    except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1='supreme court to study plea for food for all'\n",
    "sent2='supreme court to hear plea on social media hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "tf_idf1 = tf_idf_vect.fit_transform([sent1])\n",
    "tf_idf2 = tf_idf_vect.transform([sent2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x56 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 44 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94840891]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(tf_idf1,tf_idf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## size is the no of dimentsions\n",
    "## min_count specifies the min no of times a word needs to occur to be included in the model\n",
    "## workers is the number of cores on your PC\n",
    "w2v_model=gensim.models.Word2Vec(sent1,min_count=1,size=50, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "words = list(w2v_model.wv.vocab)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stupid']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('stupid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as word2vec\n",
    "model = word2vec.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8173138"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('stupid','dumb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('google_word2vec_model','rb') as pickle_file:\n",
    "    google_w2v=pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47047198]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([google_w2v['stupid']],[google_w2v['smart']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try it for a complete sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_avg_w2v(list_of_sent, w2v_model):\n",
    "    \n",
    "      ## Initialize an empty list\n",
    "    sent_vectors = []\n",
    "    ## Consider one sentence/review at a time\n",
    "    for sent in list_of_sent:\n",
    "        ## Initialize sentence vector to 0\n",
    "        sent_vec = np.zeros(300)\n",
    "        ## Initialize count of words to 0\n",
    "        cnt_words = 0\n",
    "        ## Consider the words one by one\n",
    "        for word in sent:\n",
    "            try:\n",
    "                ## Calculate the word vector using the W2V model\n",
    "                vec = w2v_model[word]\n",
    "                ## Add the word vector to the sentence vector (This is the numerator)\n",
    "                sent_vec += vec\n",
    "                ## Sum all the word counts (This is the denominator)\n",
    "                cnt_words += 1\n",
    "            except:\n",
    "                pass\n",
    "        ## Divide the numerator by the denominator to get the sentence vector\n",
    "        sent_vec /= cnt_words\n",
    "        ## Add the sentence vector in the final list\n",
    "        sent_vectors.append(sent_vec)\n",
    "    ## return the list of all the sentence vectors\n",
    "    return sent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1=\"The hippocampus is a major component of the brains of humans and other vertebrates. It belongs to the limbic system and plays important roles in the consolidation of information from short-term memory to long-term memory and spatial navigation. Humans and other mammals have two hippocampi, one in each side of the brain. The hippocampus is a part of the cerebral cortex; and in primates it is located in the medial temporal lobe, underneath the cortical surface. It contains two main interlocking parts: Ammon's horn and the dentate gyrus.\"\n",
    "sent2=\"An important part of the brains of humans and other vertebrates is the hippocampus. It's part of the limbic system and moves information from short-term to long-term memory. It also helps us move around. Humans and other mammals have two hippocampi, one on each side. The hippocampus is a part of the cerebral cortex; and in primates it is found in the medial temporal lobe, beneathe the cortical surface. It has two main interlocking parts: Ammon's horn and the dentate gyrus.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1=sent1.split()\n",
    "sent2=sent2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentvectors1 = calc_avg_w2v([sent1],google_w2v)\n",
    "sentvectors2 = calc_avg_w2v([sent2],google_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8855556763092793"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sentvectors1,sentvectors2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f227b1b7f7f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mBio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "import Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import traceback\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "class PubMedObject(object):\n",
    "    soup = None\n",
    "    url = None\n",
    "\n",
    "    # pmid is a PubMed ID\n",
    "    # url is the url of the PubMed web page\n",
    "    # search_term is the string used in the search box on the PubMed website\n",
    "    def __init__(self, pmid=None, url='', search_term=''):\n",
    "        if pmid:\n",
    "            pmid = pmid.strip()\n",
    "            url = \"http://www.ncbi.nlm.nih.gov/pubmed/%s\" % pmid\n",
    "        if search_term:\n",
    "            url = \"http://www.ncbi.nlm.nih.gov/pubmed/?term=%s\" % search_term\n",
    "        page = requests.get(url).text\n",
    "        self.soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        # set the url to be the fixed one with the PubMedID instead of the search_term\n",
    "        if search_term:\n",
    "            try:\n",
    "                url = \"http://www.ncbi.nlm.nih.gov/pubmed/%s\" % self.soup.find(\"dl\",class_=\"rprtid\").find(\"dd\").text\n",
    "            except AttributeError as e:  # NoneType has no find method\n",
    "                print(\"Error on search_term=%s\" % search_term)\n",
    "        self.url = url\n",
    "\n",
    "    def get_title(self):\n",
    "        return self.soup.find(class_=\"abstract\").find(\"h1\").text\n",
    "\n",
    "    #auths is the string that has the list of authors to return\n",
    "    def get_authors(self):\n",
    "        result = []\n",
    "        author_list = [a.text for a in self.soup.find(class_=\"auths\").findAll(\"a\")]\n",
    "        for author in author_list:\n",
    "            lname, remainder = author.rsplit(' ', 1)\n",
    "            #add periods after each letter in the first name\n",
    "            fname = \".\".join(remainder) + \".\"\n",
    "            result.append(lname + ', ' + fname)\n",
    "\n",
    "        return ', '.join(result)\n",
    "\n",
    "    def get_citation(self):\n",
    "        return self.soup.find(class_=\"cit\").text\n",
    "\n",
    "    def get_external_url(self):\n",
    "        url = None\n",
    "        doi_string = self.soup.find(text=re.compile(\"doi:\"))\n",
    "        if doi_string:\n",
    "            doi = doi_string.split(\"doi:\")[-1].strip().split(\" \")[0][:-1]\n",
    "            if doi:\n",
    "                url = \"http://dx.doi.org/%s\" % doi\n",
    "        else:\n",
    "            doi_string = self.soup.find(class_=\"portlet\")\n",
    "            if doi_string:\n",
    "                doi_string = doi_string.find(\"a\")['href']\n",
    "                if doi_string:\n",
    "                    return doi_string\n",
    "\n",
    "        return url or self.url\n",
    "\n",
    "    def render(self):\n",
    "        template_text = ''\n",
    "        with open('template.html','r') as template_file:\n",
    "            template_text = template_file.read()\n",
    "\n",
    "        try:\n",
    "            template_text = template_text.replace(\"{{ external_url }}\", self.get_external_url())\n",
    "            template_text = template_text.replace(\"{{ citation }}\", self.get_citation())\n",
    "            template_text = template_text.replace(\"{{ title }}\", self.get_title())\n",
    "            template_text = template_text.replace(\"{{ authors }}\", self.get_authors())\n",
    "            template_text = template_text.replace(\"{{ error }}\", '')\n",
    "        except AttributeError as e:\n",
    "            template_text = template_text.replace(\"{{ external_url }}\", '')\n",
    "            template_text = template_text.replace(\"{{ citation }}\", '')\n",
    "            template_text = template_text.replace(\"{{ title }}\", '')\n",
    "            template_text = template_text.replace(\"{{ authors }}\", '')\n",
    "            template_text = template_text.replace(\"{{ error }}\", '<!-- Error -->')\n",
    "\n",
    "        return template_text.encode('utf8')\n",
    "\n",
    "def start_table(f):\n",
    "    f.write('\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"resourcesTable\">\\n');\n",
    "    f.write('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<table border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\\n');\n",
    "\n",
    "def end_table(f):\n",
    "    f.write('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</table>\\n');\n",
    "    f.write('\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n');\n",
    "\n",
    "def start_accordion(f):\n",
    "    f.write('\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"accordion\">\\n');\n",
    "\n",
    "def end_accordion(f):\n",
    "    f.write('\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>\\n');\n",
    "\n",
    "def main(args):\n",
    "    try:\n",
    "        # program's main code here\n",
    "        print(\"Parsing pmids.txt...\")\n",
    "        with open('result.html', 'w') as sum_file:\n",
    "            sum_file.write('<!--\\n')\n",
    "        with open('pmids.txt','r') as pmid_file:\n",
    "        with open('result.html','a') as sum_file:\n",
    "        for pmid in pmid_file:\n",
    "            sum_file.write(pmid)\n",
    "        sum_file.write('\\n-->\\n')\n",
    "        with open('pmids.txt','r') as pmid_file:\n",
    "            h3 = False\n",
    "            h4 = False\n",
    "            table_mode = False\n",
    "            accordion_mode = False\n",
    "            with open('result.html', 'a') as sum_file:\n",
    "                for pmid in pmid_file:\n",
    "                    if pmid[:4] == \"####\":\n",
    "                        if h3 and not accordion_mode:\n",
    "                            start_accordion(sum_file)\n",
    "                            accordion_mode = True\n",
    "                        sum_file.write('\\t\\t\\t\\t\\t\\t\\t\\t\\t<h4><a href=\"#\">%s</a></h4>\\n' % pmid[4:].strip())\n",
    "                        h4 = True\n",
    "                    elif pmid[:3] == \"###\":\n",
    "                        if h4:\n",
    "                            if table_mode:\n",
    "                                end_table(sum_file)\n",
    "                                table_mode = False\n",
    "                            end_accordion(sum_file)\n",
    "                            h4 = False\n",
    "                            accordion_mode = False\n",
    "                        elif h3:\n",
    "                            end_table(sum_file)\n",
    "                            table_mode = False\n",
    "                        sum_file.write('\\t\\t\\t\\t\\t\\t\\t\\t<h3><a href=\"#\">%s</a></h3>\\n' % pmid[3:].strip())\n",
    "                        h3 = True                        \n",
    "                    elif pmid.strip():\n",
    "                        if (h3 or h4) and not table_mode:\n",
    "                            start_table(sum_file)\n",
    "                            table_mode = True\n",
    "                        if pmid[:4] == \"http\":\n",
    "                            if pmid[:18] == \"http://dx.doi.org/\":\n",
    "                                sum_file.write(PubMedObject(search_term=pmid[18:]).render())\n",
    "                            else:\n",
    "                                print(\"url=%s\" % pmid)\n",
    "                                p = PubMedObject(url=pmid).render()\n",
    "                                sum_file.write(p)\n",
    "                                print(p)\n",
    "                        elif pmid.isdigit():\n",
    "                            sum_file.write(PubMedObject(pmid).render())\n",
    "                        else:\n",
    "                            sum_file.write(PubMedObject(search_term=pmid).render())\n",
    "                if h3:\n",
    "                    if h4:\n",
    "                        end_table(sum_file)\n",
    "                        end_accordion(sum_file)\n",
    "                    else:\n",
    "                        end_table(sum_file)\n",
    "            pmid_file.close()\n",
    "        print(\"Done!\")\n",
    "\n",
    "    except BaseException as e:\n",
    "        print traceback.format_exc()\n",
    "        print \"Error: %s %s\" % (sys.exc_info()[0], e.args)\n",
    "        return 1\n",
    "    except:\n",
    "        # error handling code here\n",
    "        print \"Error: %s\" % sys.exc_info()[0]\n",
    "        return 1  # exit on error\n",
    "    else:\n",
    "        raw_input(\"Press enter to exit.\")\n",
    "        return 0  # exit errorlessly\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.exit(main(sys.ab\n",
    "                  rgv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f227b1b7f7f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mBio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "import Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'biopython'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8c1c27adb22a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbiopython\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'biopython'"
     ]
    }
   ],
   "source": [
    "import biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip insta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
